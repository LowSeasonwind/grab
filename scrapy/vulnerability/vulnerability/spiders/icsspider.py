#coding=utf-8

import sys
import exceptions
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors.lxmlhtml import LxmlLinkExtractor
from scrapy.selector import Selector
from vulnerability.items import ics
if sys.getdefaultencoding() != 'utf-8':
    reload(sys)
    sys.setdefaultencoding('utf-8')

# 工控漏洞 ics.cnvd 不用全部解析，只需解析出cnvd,在库里标示该cnvd对应的是工控软件就行


class icsspider(CrawlSpider):
    download_delay = 3
    retry_times = 10
    name = 'ics'
    start_urls = ['http://ics.cnvd.org.cn/?max=20&offset=400']
    # start_urls = ['http://www.cnvd.org.cn/flaw/list.htm?max=20&offset=3240']
    allowed_domains = ['ics.cnvd.org.cn','www.cnvd.org.cn']

    rules = (Rule(LxmlLinkExtractor(allow=('/\?max=\d+',),
                                    restrict_xpaths=("//a[@class='nextLink']",))),
             Rule(LxmlLinkExtractor(allow=('/flaw/show/',),
                                    restrict_xpaths=("//tbody[@id='tr']",)),
                  follow=True, callback='parse_item'))

    def parse_item(self,response):
        sel = Selector(response)
        try:
            item = ics()
            item['cnvd'] = ''.join(sel.xpath("//table[@class='gg_detail']\
                            /tbody/tr[1]/td[2]/text()").extract()).strip()
            yield item
        except exceptions:
            print 'url: %s 解析出错' % response.url
        pass